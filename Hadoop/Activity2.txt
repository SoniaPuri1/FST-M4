# Opens file01.txt in vim. Paste the text from above and save/exit.
$ vim file01.txt

# Copy the file into the HDFS
$ hdfs dfs -put ./file01.txt /user/root/


wordcount.pig
-- Load input file from HDFS
inputFile = LOAD 'hdfs:///user/root/file01.txt' AS (line);
-- Tokeize each word in the file (Map)
words = FOREACH inputFile GENERATE FLATTEN(TOKENIZE(line)) AS word;
-- Combine the words from the above stage
grpd = GROUP words BY word;
-- Count the occurence of each word (Reduce)
cntd = FOREACH grpd GENERATE group, COUNT(words);
-- Store the result in HDFS
STORE cntd INTO 'hdfs:///user/root/results';



$ pig wordcount.pig
$ bin/hdfs dfs -cat /user/root/results/part-r-00000